{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yirui.wang/anaconda3/envs/rtnet/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import pathlib\n",
    "import os, sys\n",
    "from os.path import join, isfile, dirname, basename, exists\n",
    "import pickle\n",
    "import shutil\n",
    "import random\n",
    "from itertools import repeat\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "import multiprocessing\n",
    "\n",
    "import cc3d\n",
    "import SimpleITK as sitk\n",
    "import torchio as tio\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "from skimage.morphology import disk, ball, octagon, octahedron\n",
    "\n",
    "# relative import of get_recist\n",
    "from rtnet.utils.get_recist import get_RECIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/78739', '/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/128367', '/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/163816', '/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/239962', '/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/165081']\n"
     ]
    }
   ],
   "source": [
    "lns_suffix = \"_CT_TaskLNSSeg_pred.nii.gz\"\n",
    "data_root = \"/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred\"\n",
    "patient_folder = [os.path.join(data_root, p) for p in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, p)) and p.isnumeric()]\n",
    "print(patient_folder[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load testing list and filter out training cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/100241',\n",
       "  'T07'),\n",
       " ('/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/100306',\n",
       "  'T01'),\n",
       " ('/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/100306',\n",
       "  'T03.P'),\n",
       " ('/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/100346',\n",
       "  'T05'),\n",
       " ('/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred/100346',\n",
       "  'T07')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = '/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/Cleaned_SichuanData_CorrectHU_Pred'\n",
    "dataset_json_path = \"/data/yirui/datasets/LN_classify/rtNetData/images/rtNet_raw_data/Task020_Chuanzhong_9LNS\"\n",
    "with open(os.path.join(dataset_json_path, \"dataset.json\"), 'rb') as f:\n",
    "    dataset = json.load(f)\n",
    "testset = dataset['test']\n",
    "test_patient = [(os.path.join(data_root, p.split('/')[2]), p.split('_')[1]) for p in testset]\n",
    "print(len(test_patient))\n",
    "test_patient[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RECIST-based clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_suffix = \"_LN_Mediastinal.nii.gz\"\n",
    "lns_suffix = \"_CT_TaskLNSSeg_pred.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_LNS = {\n",
    "    1: 'T01',\n",
    "    2: 'T01',\n",
    "    3: 'T02',\n",
    "    4: 'T02',\n",
    "    6: 'T03.P',\n",
    "    7: 'T04',\n",
    "    8: 'T04',\n",
    "    9: 'T05',\n",
    "    11: 'T07',\n",
    "    12: 'T08',\n",
    "}\n",
    "\n",
    "lns_to_label = {v:k for k,v in label_to_LNS.items()}\n",
    "\n",
    "lns_to_df_col_map = {\n",
    "    'T01': ['Meta LNs 1L', 'Meta LNs 1R'],\n",
    "    'T02': ['Meta LNs 2L', 'Meta LNs 2R'],\n",
    "    'T03.P': ['Meta LNs 8U'],\n",
    "    'T04': ['Meta LNs 4L', 'Meta LNs 4R'],\n",
    "    'T05': ['Meta LNs 5'],\n",
    "    'T07': ['Meta LNs 7'],\n",
    "    'T08': ['Meta LNs 8M', 'Meta LNs 8L']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diameter_stats(data, spacing):\n",
    "    labels = np.unique(data.reshape(-1))\n",
    "    labels = np.delete(labels, np.where(labels == 0))\n",
    "    num_of_label = len(labels)\n",
    "    \n",
    "    short_diameters = []\n",
    "    for n in labels:\n",
    "        tmp_dat = np.copy(data)\n",
    "        tmp_dat[tmp_dat != n] = 0\n",
    "        tmp_dat[tmp_dat > 0] = 1\n",
    "        short_d = get_RECIST(tmp_dat.transpose(2,0,1), spacing[0])\n",
    "        short_diameters.append(short_d)\n",
    "    return short_diameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2401 cases\n"
     ]
    }
   ],
   "source": [
    "def process_patient(case, df, all_stats):\n",
    "    folder, lns_name = case\n",
    "    cur_patient = {}\n",
    "    patient_id = folder.split('/')[-1]\n",
    "    lymph_node_mask_pth = os.path.join(folder, patient_id + ln_suffix)\n",
    "    lns_mask_pth = os.path.join(folder, patient_id + lns_suffix)\n",
    "    \n",
    "    ln_mask = tio.LabelMap(lymph_node_mask_pth)\n",
    "    lns_mask = tio.LabelMap(lns_mask_pth)\n",
    "\n",
    "    # statistics for patient-wise lymph node\n",
    "    ln_dat = ln_mask.numpy().squeeze().astype(int)\n",
    "    ln_siz = ln_mask.spacing # W, H, D\n",
    "    ln_vox = np.prod(ln_siz)\n",
    "    \n",
    "    lns_dat = lns_mask.numpy().squeeze().astype(int)\n",
    "\n",
    "    cur_lns_dat = (lns_dat == lns_to_label[lns_name]).astype(int)\n",
    "    cur_ln_dat = ln_dat * cur_lns_dat\n",
    "    ln_short_diameter_stats = get_diameter_stats(cur_ln_dat, ln_mask.spacing)\n",
    "    max_recist = np.max(ln_short_diameter_stats) if ln_short_diameter_stats else 0\n",
    "    \n",
    "    df_row = df.loc[int(patient_id)]\n",
    "    try:\n",
    "        labels = (np.sum([int(df_row[p]) for p in lns_to_df_col_map[lns_name]]) > 0) * 1.0\n",
    "    except:\n",
    "        labels = [df_row[p] for p in lns_to_df_col_map[lns_name]]\n",
    "        print(labels)\n",
    "    # labels = 1 if 1 in labels else 0\n",
    "        \n",
    "    all_stats[patient_id + '_' + lns_name] = [max_recist, labels]\n",
    "\n",
    "csv_pth = \"/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/ChuanzhongClinical_mined_with_MRN.csv\"\n",
    "df_main = pd.read_csv(csv_pth)\n",
    "df_main = df_main.set_index('MRN')\n",
    "df_main = df_main.drop_duplicates()\n",
    "\n",
    "manager = mp.Manager()\n",
    "all_stats = manager.dict()\n",
    "pool = multiprocessing.Pool(processes=30, maxtasksperchild=1)\n",
    "pool.map(partial(process_patient, df=df_main, all_stats=all_stats), test_patient)\n",
    "pool.close()\n",
    "\n",
    "all_results = dict(all_stats)\n",
    "print(\"Total {} cases\".format(len(all_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_pth = \"/data/yirui/datasets/LN_classify/Sichuan_thoracic_LN/ChuanzhongClinical_mined_with_MRN.csv\"\n",
    "# df_main = pd.read_csv(csv_pth)\n",
    "# df_main = df_main.set_index('MRN')\n",
    "# df_main = df_main.drop_duplicates()\n",
    "\n",
    "# manager = mp.Manager()\n",
    "# all_stats = manager.dict()\n",
    "# pool = multiprocessing.Pool(processes=30, maxtasksperchild=1)\n",
    "# pool.map(partial(process_patient, df=df_main, all_stats=all_stats), test_patient)\n",
    "# pool.close()\n",
    "\n",
    "# all_results = dict(all_stats)\n",
    "# print(\"Total {} cases\".format(len(all_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_station_pred = defaultdict(list)\n",
    "for k, v in all_results.items():\n",
    "    cur_lns = k.split('_')[1]\n",
    "    per_station_pred[cur_lns].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.152578711509705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(per_station_pred['T02'])[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LNS T02 pos ratio 83.0 / 383\n",
      "LNS T02 -- Accuracy: 0.7963, recall: 0.2651, specificity: 0.9433\n",
      "LNS T05 pos ratio 6.0 / 354\n",
      "LNS T05 -- Accuracy: 0.9746, recall: 0.0000, specificity: 0.9914\n",
      "LNS T07 pos ratio 54.0 / 337\n",
      "LNS T07 -- Accuracy: 0.5994, recall: 0.5556, specificity: 0.6078\n",
      "LNS T01 pos ratio 18.0 / 335\n",
      "LNS T01 -- Accuracy: 0.8925, recall: 0.3889, specificity: 0.9211\n",
      "LNS T03.P pos ratio 17.0 / 343\n",
      "LNS T03.P -- Accuracy: 0.9417, recall: 0.0000, specificity: 0.9908\n",
      "LNS T08 pos ratio 58.0 / 338\n",
      "LNS T08 -- Accuracy: 0.8136, recall: 0.1207, specificity: 0.9571\n",
      "LNS T04 pos ratio 13.0 / 311\n",
      "LNS T04 -- Accuracy: 0.8682, recall: 0.2308, specificity: 0.8960\n"
     ]
    }
   ],
   "source": [
    "for k, v in per_station_pred.items():\n",
    "    pred_label = [[p[0], p[1]] for p in v]\n",
    "    pred_label = np.array(pred_label)\n",
    "    preds = (pred_label[:, 0] > 9) * 1.0\n",
    "    labels = pred_label[:, 1]\n",
    "    acc = np.sum(preds == labels) / labels.shape[0]\n",
    "    recall = np.sum(preds[labels == 1]) / np.sum(labels)\n",
    "    specificity = 1 - np.sum(preds[labels == 0]) / np.sum(labels == 0)\n",
    "    print(\"LNS {} pos ratio {} / {}\".format(k, np.sum(labels), labels.shape[0]))\n",
    "    print(\"LNS {} -- Accuracy: {:.4f}, recall: {:.4f}, specificity: {:.4f}\".format(k, acc, recall, specificity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3843dd14ce351460c94cdae9c3ed46da9f8071802e369f3b44662336a590d55a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
